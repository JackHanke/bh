{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def1b67d",
   "metadata": {},
   "source": [
    "# Training Workbook for Supercomputer Environment\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c008e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup and configs\n",
    "# imports\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pylot as plt\n",
    "# global variables\n",
    "global notebook\n",
    "global axisym,set_cart,axisym,REF_1,REF_2,REF_3,set_cart,D,print_fieldlines\n",
    "global lowres1,lowres2,lowres3, RAD_M1, RESISTIVE, export_raytracing_GRTRANS, export_raytracing_RAZIEH,r1,r2,r3\n",
    "global r_min, r_max, theta_min, theta_max, phi_min,phi_max, do_griddata, do_box, check_files, kerr_schild\n",
    "\n",
    "notebook = 1\n",
    "\n",
    "harm_directory = '/global/u1/j/jackh/bh/harm2d'\n",
    "os.chdir(harm_directory)\n",
    "\n",
    "%run -i setup.py build_ext --inplace\n",
    "%run -i pp.py build_ext --inplace\n",
    "\n",
    "# set params\n",
    "lowres1 = 1 # \n",
    "lowres2 = 1 # \n",
    "lowres3 = 1 # \n",
    "r_min, r_max = 1.0, 100.0\n",
    "theta_min, theta_max = 0.0, 9\n",
    "phi_min, phi_max = -1, 9\n",
    "do_box=0\n",
    "set_cart=0\n",
    "set_mpi(0)\n",
    "axisym=1\n",
    "print_fieldlines=0\n",
    "export_raytracing_GRTRANS=0\n",
    "export_raytracing_RAZIEH=0\n",
    "kerr_schild=0\n",
    "DISK_THICKNESS=0.03\n",
    "check_files=1\n",
    "notebook=1\n",
    "interpolate_var=0\n",
    "AMR = 0 # get all data in grid\n",
    "\n",
    "print('Imports and setup done.')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a22f0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# training utilities\n",
    "from utils.sc_utils import custom_batcher, tensorize_globals\n",
    "from models.cnn.cnn import CNN_3D\n",
    "\n",
    "# path to dumps\n",
    "dumps_path = '/pscratch/sd/l/lalakos/ml_data_rc300/reduced'\n",
    "os.chdir(dumps_path)\n",
    "# number of data points\n",
    "num_dumps = 10 - 1\n",
    "# batch size\n",
    "batch_size = 2\n",
    "# number of epochs\n",
    "num_epochs = 2\n",
    "# set model\n",
    "model = CNN_3D()\n",
    "# set loss\n",
    "optim = torch.optim.Adam(params=model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# get indexes for training data\n",
    "train_indexes, validation_indexes = custom_batcher(\n",
    "    batch_size=batch_size,\n",
    "    num_dumps=num_dumps,\n",
    "    split = 0.8,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ## Training\n",
    "    model.train()\n",
    "    epoch_train_loss = []\n",
    "\n",
    "    # shuffle training indexes\n",
    "    np.random.shuffle(train_indexes)\n",
    "\n",
    "    # list of average train/validation losses after each epoch\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    prog_bar = tqdm(train_indexes.reshape(-1, batch_size))\n",
    "    for batch_indexes in prog_bar:\n",
    "        ## fetch and tensorize data\n",
    "        # NOTE everything is a global variable so it has to be this way. im sorry\n",
    "        batch_data, label_data = [], []\n",
    "        # batch_idx is the dump number\n",
    "        for batch_idx in batch_indexes:\n",
    "            ## get data frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx)\n",
    "            rpar_new(batch_idx)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            batch_data.append(data_tensor)\n",
    "\n",
    "            ## get label frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx+1)\n",
    "            rpar_new(batch_idx+1)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx+1)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            label_data.append(data_tensor)\n",
    "\n",
    "        # final tensorize\n",
    "        batch_data = torch.cat(batch_data, dim=0)\n",
    "        label_data = torch.cat(label_data, dim=0)\n",
    "\n",
    "        ## train model\n",
    "        # make prediction\n",
    "        pred = model.forward(batch_data)\n",
    "        # compute loss\n",
    "        loss_value = loss_fn(pred, label_data)\n",
    "        epoch_train_loss.append(loss_value)\n",
    "        # backprop\n",
    "        loss_value.backward()\n",
    "        # update paramts\n",
    "        optim.step()\n",
    "\n",
    "    # training loss tracking\n",
    "    avg_loss_after_epoch = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    train_losses.append(avg_loss_after_epoch)\n",
    "    print(f\"Train loss value: {avg_loss_after_epoch}\")\n",
    "\n",
    "\n",
    "    ## Validation\n",
    "    model.eval()\n",
    "    epoch_valid_loss = []\n",
    "\n",
    "    prog_bar = tqdm(validation_indexes.reshape(-1, batch_size))\n",
    "    for batch_indexes in prog_bar:\n",
    "        ## fetch and tensorize data\n",
    "        # NOTE everything is a global variable so it has to be this way. im sorry\n",
    "        batch_data, label_data = [], []\n",
    "        # batch_idx is the dump number\n",
    "        for batch_idx in batch_indexes:\n",
    "            ## get data frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx)\n",
    "            rpar_new(batch_idx)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            batch_data.append(data_tensor)\n",
    "\n",
    "            ## get label frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx+1)\n",
    "            rpar_new(batch_idx+1)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx+1)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            label_data.append(data_tensor)\n",
    "\n",
    "        # final tensorize\n",
    "        batch_data = torch.cat(batch_data, dim=0)\n",
    "        label_data = torch.cat(label_data, dim=0)\n",
    "\n",
    "        # make prediction\n",
    "        pred = model.forward(batch_data)\n",
    "\n",
    "        # compute loss\n",
    "        loss_value = loss_fn(pred, label_data)\n",
    "        epoch_valid_loss.append(loss_value)\n",
    "        \n",
    "    avg_vloss_after_epoch = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    valid_losses.append(avg_vloss_after_epoch)\n",
    "    print(f\"Valid loss value: {avg_loss_after_epoch}\")\n",
    "\n",
    "    # plot learning\n",
    "    plt.plot([i for i in range(len(train_losses))], [loss.item() for loss in train_losses], label='Train Loss')\n",
    "    # plt.plot([i for i in range(len(train_losses))], [avg_baseline_loss for _ in range(len(train_losses))], label='Predicting Avg Loss', linestyle='dashed')\n",
    "    plt.plot([i for i in range(len(valid_losses))], [loss.item() for loss in valid_losses], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Curve')\n",
    "    plt.xlabel(f'Number of Batches')\n",
    "    plt.ylabel(f'Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcbafe",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a256c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holy fuck TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msai339",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
