{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def1b67d",
   "metadata": {},
   "source": [
    "# Training Workbook for Supercomputer Environment\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c008e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running setup scripts...\n",
      "Starting single GPU training\n",
      "--- Training script running! ---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv3d: 2, MaxPool3d: 2, ReLU: 2, Conv3d: 2, MaxPool3d: 2, ReLU: 2, Flatten: 2, Linear: 2, Sigmoid: 2, Flatten: 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torchinfo/torchinfo.py:295\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u1/j/jackh/bh/harm2d/models/cnn/cnn.py:189\u001b[39m, in \u001b[36mJACK_CNN_3D.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    188\u001b[39m x = \u001b[38;5;28mself\u001b[39m.encoder(x)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2x75 and 64512x75)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u1/j/jackh/bh/harm2d/pp.py:6387\u001b[39m\n\u001b[32m   6385\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6386\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting single GPU training\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m6387\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6389\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m   6390\u001b[39m \u001b[38;5;66;03m# save_path = os.environ['HOME']+f'/bh/movies/sc_frames/'\u001b[39;00m\n\u001b[32m   6391\u001b[39m \u001b[38;5;66;03m# plot_and_save_range(start=3000, end=3050, save_path=save_path)\u001b[39;00m\n\u001b[32m   6392\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u1/j/jackh/bh/harm2d/pp.py:6043\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   6040\u001b[39m model = JACK_CNN_3D().to(device)\n\u001b[32m   6041\u001b[39m \u001b[38;5;66;03m# model = CNN_DEPTH().to(device)\u001b[39;00m\n\u001b[32m   6042\u001b[39m \u001b[38;5;66;03m# model = CNN_DEPTH().to(device)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6043\u001b[39m summary_str = \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6044\u001b[39m logger.info(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(summary_str))\n\u001b[32m   6046\u001b[39m \u001b[38;5;66;03m# set loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torchinfo/torchinfo.py:223\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m validate_user_params(\n\u001b[32m    217\u001b[39m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[32m    218\u001b[39m )\n\u001b[32m    220\u001b[39m x, correct_input_size = process_input(\n\u001b[32m    221\u001b[39m     input_data, input_size, batch_dim, device, dtypes\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m summary_list = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m formatting = FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[32m    227\u001b[39m results = ModelStatistics(\n\u001b[32m    228\u001b[39m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/scenv/lib/python3.11/site-packages/torchinfo/torchinfo.py:304\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    303\u001b[39m     executed_layers = [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer.executed]\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv3d: 2, MaxPool3d: 2, ReLU: 2, Conv3d: 2, MaxPool3d: 2, ReLU: 2, Flatten: 2, Linear: 2, Sigmoid: 2, Flatten: 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 6.3288185596466064\n",
      "Imports and setup done.\n"
     ]
    }
   ],
   "source": [
    "## Setup and configs\n",
    "# imports\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# global variables\n",
    "global notebook\n",
    "global axisym,set_cart,axisym,REF_1,REF_2,REF_3,set_cart,D,print_fieldlines\n",
    "global lowres1,lowres2,lowres3, RAD_M1, RESISTIVE, export_raytracing_GRTRANS, export_raytracing_RAZIEH,r1,r2,r3\n",
    "global r_min, r_max, theta_min, theta_max, phi_min,phi_max, do_griddata, do_box, check_files, kerr_schild\n",
    "\n",
    "notebook = 1\n",
    "\n",
    "# total data is shape (10000, 224, 48, 96)\n",
    "harm_directory = os.environ['HOME']+f'/bh/harm2d'\n",
    "os.chdir(harm_directory)\n",
    "\n",
    "print(f'Running setup scripts...')\n",
    "start_time = time.time()\n",
    "%run -i setup.py build_ext --inplace\n",
    "%run -i pp.py build_ext --inplace\n",
    "print(f\"Execution time: {time.time() - start_time}\")\n",
    "\n",
    "# set params\n",
    "lowres1 = 1 # \n",
    "lowres2 = 1 # \n",
    "lowres3 = 1 # \n",
    "r_min, r_max = 1.0, 100.0\n",
    "theta_min, theta_max = 0.0, 9\n",
    "phi_min, phi_max = -1, 9\n",
    "do_box=0\n",
    "set_cart=0\n",
    "set_mpi(0)\n",
    "axisym=1\n",
    "print_fieldlines=0\n",
    "export_raytracing_GRTRANS=0\n",
    "export_raytracing_RAZIEH=0\n",
    "kerr_schild=0\n",
    "DISK_THICKNESS=0.03\n",
    "check_files=1\n",
    "notebook=1\n",
    "interpolate_var=0\n",
    "AMR = 0 # get all data in grid\n",
    "\n",
    "print('Imports and setup done.')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a22f0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55d6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 28 but got size 224 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     84\u001b[39m     label_data.append(data_tensor)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# final tensorize\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m batch_data = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     88\u001b[39m label_data = torch.cat(label_data, dim=\u001b[32m0\u001b[39m).to(device)\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m## train model\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# make prediction\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 0. Expected size 28 but got size 224 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# training utilities\n",
    "from utils.sc_utils import custom_batcher, tensorize_globals\n",
    "from models.cnn.cnn import CNN_3D\n",
    "\n",
    "# path to dumps\n",
    "dumps_path = '/pscratch/sd/l/lalakos/ml_data_rc300/reduced'\n",
    "os.chdir(dumps_path)\n",
    "# number of data points\n",
    "num_dumps = 11 - 1\n",
    "# batch size\n",
    "batch_size = 2\n",
    "# number of epochs\n",
    "num_epochs = 2\n",
    "\n",
    "# access device, cuda device if accessible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# set model\n",
    "model = CNN_3D().to(device)\n",
    "# set loss\n",
    "optim = torch.optim.Adam(params=model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# get indexes for training data\n",
    "train_indexes, validation_indexes = custom_batcher(\n",
    "    batch_size=batch_size,\n",
    "    num_dumps=num_dumps,\n",
    "    split = 0.8,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "num_train_batches = len(train_indexes)//batch_size\n",
    "num_valid_batches = len(validation_indexes)//batch_size\n",
    "\n",
    "best_validation = float('inf')\n",
    "\n",
    "rgdump_griddata(dumps_path)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ## Training\n",
    "    model.train()\n",
    "    epoch_train_loss = []\n",
    "\n",
    "    # shuffle training indexes\n",
    "    np.random.shuffle(train_indexes)\n",
    "\n",
    "    # list of average train/validation losses after each epoch\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    prog_bar = tqdm(enumerate(train_indexes.reshape(-1, batch_size)), total=num_train_batches)\n",
    "    for batch_num, batch_indexes in prog_bar:\n",
    "        ## fetch and tensorize data\n",
    "        # NOTE everything is a global variable so it has to be this way. im sorry\n",
    "        batch_data, label_data = [], []\n",
    "        # batch_idx is the dump number\n",
    "        for batch_idx in batch_indexes:\n",
    "\n",
    "            # at every batch of size batch_size, we need to read in 2 * batch_size dumps\n",
    "            \n",
    "            ## get data frame\n",
    "            # get data into global context NOTE this is really slow\n",
    "            rblock_new(batch_idx)\n",
    "            rpar_new(batch_idx)\n",
    "            rdump_griddata(dumps_path, batch_idx)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            batch_data.append(data_tensor)\n",
    "\n",
    "            ## get label frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx+1)\n",
    "            rpar_new(batch_idx+1)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx+1)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            label_data.append(data_tensor)\n",
    "\n",
    "        # final tensorize\n",
    "        batch_data = torch.cat(batch_data, dim=0).to(device)\n",
    "        label_data = torch.cat(label_data, dim=0).to(device)\n",
    "\n",
    "        ## train model\n",
    "        # make prediction\n",
    "        pred = model.forward(batch_data)\n",
    "        # compute loss\n",
    "        loss_value = loss_fn(pred, label_data)\n",
    "        epoch_train_loss.append(loss_value)\n",
    "        # backprop\n",
    "        loss_value.backward()\n",
    "        # update paramts\n",
    "        optim.step()\n",
    "\n",
    "        prog_bar.set_description(f'Train batch {batch_num+1} completed with loss {loss_value.item():.4f}')\n",
    "\n",
    "    # training loss tracking\n",
    "    avg_loss_after_epoch = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    train_losses.append(avg_loss_after_epoch)\n",
    "    print(f\"Train loss value: {avg_loss_after_epoch}\")\n",
    "\n",
    "\n",
    "    ## Validation\n",
    "    model.eval()\n",
    "    epoch_valid_loss = []\n",
    "\n",
    "    prog_bar = tqdm(enumerate(validation_indexes.reshape(-1, batch_size)), total=num_valid_batches)\n",
    "    for batch_num, batch_indexes in prog_bar:\n",
    "        ## fetch and tensorize data\n",
    "        # NOTE everything is a global variable so it has to be this way. im sorry\n",
    "        batch_data, label_data = [], []\n",
    "        # batch_idx is the dump number\n",
    "        for batch_idx in batch_indexes:\n",
    "            ## get data frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx)\n",
    "            rpar_new(batch_idx)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            batch_data.append(data_tensor)\n",
    "\n",
    "            ## get label frame\n",
    "            # get data into global context\n",
    "            rblock_new(batch_idx+1)\n",
    "            rpar_new(batch_idx+1)\n",
    "            rgdump_griddata(dumps_path)\n",
    "            rdump_griddata(dumps_path, batch_idx+1)\n",
    "            # format data as tensor\n",
    "            data_tensor = tensorize_globals(rho=rho, ug=ug, uu=uu, B=B)\n",
    "            # add to batch\n",
    "            label_data.append(data_tensor)\n",
    "\n",
    "        # final tensorize\n",
    "        batch_data = torch.cat(batch_data, dim=0).to(device)\n",
    "        label_data = torch.cat(label_data, dim=0).to(device)\n",
    "\n",
    "        # make prediction\n",
    "        pred = model.forward(batch_data)\n",
    "\n",
    "        # compute loss\n",
    "        loss_value = loss_fn(pred, label_data)\n",
    "        epoch_valid_loss.append(loss_value)\n",
    "        \n",
    "        prog_bar.set_description(f'Validation batch {batch_num+1} completed with loss {loss_value.item():.4f}.')\n",
    "        \n",
    "    avg_vloss_after_epoch = sum(epoch_train_loss)/len(epoch_train_loss)\n",
    "    valid_losses.append(avg_vloss_after_epoch)\n",
    "    print(f\"Valid loss value: {avg_loss_after_epoch}\")\n",
    "\n",
    "    # checkpointing\n",
    "    if avg_vloss_after_epoch < best_validation:\n",
    "        best_validation = avg_vloss_after_epoch\n",
    "        save_path = os.environ['HOME'] + '/bh/' + model.save_path\n",
    "        model.save(save_path=save_path)\n",
    "\n",
    "# plot learning\n",
    "plt.plot([i for i in range(len(train_losses))], [loss.item() for loss in train_losses], label='Train Loss')\n",
    "# plt.plot([i for i in range(len(train_losses))], [avg_baseline_loss for _ in range(len(train_losses))], label='Predicting Avg Loss', linestyle='dashed')\n",
    "plt.plot([i for i in range(len(valid_losses))], [loss.item() for loss in valid_losses], label='Validation Loss')\n",
    "plt.title(f'Training and Validation Curve')\n",
    "plt.xlabel(f'Number of Batches')\n",
    "plt.ylabel(f'Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcbafe",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6754855-104f-4747-ba1d-6709eafef009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# load in model\n",
    "import os\n",
    "import torch\n",
    "from models.cnn.cnn import CNN_3D\n",
    "\n",
    "# access device, cuda device if accessible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_path = os.environ['HOME'] + '/bh/models/cnn/saves/3dcnn_v0.0.0.pth'\n",
    "model = CNN_3D()\n",
    "model.load_state_dict(torch.load(f=model_path))\n",
    "model = model.to(device)\n",
    "print(f'Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a256c43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'animate_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     12\u001b[0m predictions, latents \u001b[38;5;241m=\u001b[39m make_prediciton_frames(\n\u001b[1;32m     13\u001b[0m     net\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     14\u001b[0m     first_frame\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# animate\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43manimate_preds\u001b[49m(\n\u001b[1;32m     22\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m predictions, \n\u001b[1;32m     23\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./movies/preds_movie.gif\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m     cb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'animate_preds' is not defined"
     ]
    }
   ],
   "source": [
    "from utils.anim import make_prediciton_frames\n",
    "\n",
    "os.chdir(os.environ['HOME'] + '/bh/')\n",
    "\n",
    "# access device, cuda device if accessible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "save_path = os.environ['HOME']+'/bh/data.pkl'\n",
    "data = torch.load(f=save_path)\n",
    "# print(data.shape)\n",
    "\n",
    "predictions, latents = make_prediciton_frames(\n",
    "    net=model,\n",
    "    first_frame=data[0].unsqueeze(0), \n",
    "    make_latents=False,\n",
    "    num_frames=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# animate\n",
    "# animate_preds(\n",
    "#     predictions = predictions, \n",
    "#     save_path = './movies/preds_movie.gif',\n",
    "#     cb = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2578c42-a0f7-409f-b666-727a4047a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scenvkernel",
   "language": "python",
   "name": "scenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
